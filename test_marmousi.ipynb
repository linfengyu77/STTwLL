{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dict_layer import Model, dictloss\n",
    "import os\n",
    "import NES\n",
    "from utlis import survey_deisgn, patchSamp, getPatches, rmse\n",
    "from LsTomo import conventional_tomo2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from itkm import itkm\n",
    "from omp_n import omp_n\n",
    "from scipy.sparse import csc_matrix\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "####################################################################################\n",
    "np.random.seed(123)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "####################################################################################\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float64)\n",
    "print(torch.cuda.device_count(),torch.cuda.get_device_properties(0), cuda, device)\n",
    "####################################################################################\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "####################################################################################\n",
    "save_path = './Marmousi_smooth3_noise5/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Marmousi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vel2D = NES.misc.Marmousi(smooth=3, section=[[600, 900], None]) # importing from NES package data\n",
    "vmin, vmax = Vel2D.min, Vel2D.max\n",
    "xmin, zmin = Vel2D.xmin\n",
    "xmax, zmax = Vel2D.xmax\n",
    "nx, nz = 100, 100\n",
    "x = np.linspace(xmin, xmax, nx)\n",
    "z = np.linspace(zmin, zmax, nz)\n",
    "Xr_2d = np.stack(np.meshgrid(x, z, indexing='ij'), axis=-1)\n",
    "V_2d = Vel2D(Xr_2d)\n",
    "sTrue = np.transpose(1/V_2d)\n",
    "plt.imshow(sTrue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vel2D = NES.misc.Marmousi(smooth=3)\n",
    "# vmin, vmax = Vel2D.min, Vel2D.max\n",
    "# xmin, zmin = Vel2D.xmin\n",
    "# xmax, zmax = Vel2D.xmax\n",
    "# nx, nz = 4000, 2000\n",
    "# x = np.linspace(xmin, xmax, nx)\n",
    "# z = np.linspace(zmin, zmax, nz)\n",
    "# Xr_2d = np.stack(np.meshgrid(x, z, indexing='ij'), axis=-1)\n",
    "# V_2d = Vel2D(Xr_2d)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot()\n",
    "# im = ax.imshow(np.transpose(1/V_2d))\n",
    "# ax.set_xticklabels([])\n",
    "# ax.set_yticklabels([])\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(im, cax=cax, fraction=0.046)\n",
    "# plt.savefig(save_path + 'Marmousi.pdf')  \n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting stations and get trace-rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tarr, A, vb, vb2 = survey_deisgn(64, sTrue, save_path=save_path)\n",
    "noiseFrac = 0.05                                          # noise STD as fraction of mean value of travel time (0=noise free case)                                                \n",
    "stdNoise = np.mean(Tarr) * noiseFrac\n",
    "noise    = stdNoise * np.random.randn(Tarr.shape[0], Tarr.shape[1])\n",
    "Tarr_n   = Tarr + noise                                  \n",
    "Asum = np.sum(A, axis=1, keepdims=True)                                    # estimating referense slowness from travel time observations\n",
    "invAsum = np.linalg.pinv(Asum)\n",
    "sRef = invAsum @ Tarr_n                                     # Tarr_n: 1x2016 A: 2016x10000 vb:10000x1\n",
    "#######################################################################################\n",
    "if noiseFrac == 0:                  \n",
    "    eta  = 0.1                                              # conventional \\eta regularization parameter\n",
    "    L    = 10                                               # smoothness length scale\n",
    "else:\n",
    "    eta  = 10      \n",
    "    L    = 20                                              \n",
    "#######################################################################################\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "criterion = dictloss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100], gamma=0.1)\n",
    "\n",
    "w1, w2 = sTrue.shape\n",
    "patch_size = 20\n",
    "patches  = getPatches(w1, w2, patch_size)        # calculating image patch indices\n",
    "percZero = patchSamp(A, patches)       # percentage ray coverage in patches\n",
    "ss = np.zeros((vb.size, 1))\n",
    "npp, npatches = patches.shape\n",
    "nrays, npix   = A.shape\n",
    "normError = [np.linalg.norm(Tarr_n - A @ (ss + sRef))]\n",
    "print('Trave time initinal error: {}'.format(normError))\n",
    "############################################################\n",
    "epoch = 50\n",
    "natom = 150\n",
    "iters = 50\n",
    "lam2  = 0\n",
    "D_sparse = 1\n",
    "C_sparse = 1\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training or dictionary updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = conventional_tomo2(eta, L, A, sRef, Tarr_n, sTrue, vb)\n",
    "Y  = ds.flatten()[patches]\n",
    "meanY = np.mean(Y, axis=0, keepdims=True)\n",
    "Yc = Y - meanY\n",
    "D0 = itkm(Yc, natom, D_sparse)\n",
    "X  = omp_n(D0, Yc, C_sparse)\n",
    "D0 = torch.tensor(D0).to(device)\n",
    "RMSE = []\n",
    "###################### Ditcionary Learning ###############################\n",
    "for j in range(epoch):\n",
    "    D = model(D0)\n",
    "    loss = criterion(D, X, ss, vb, npatches, patches, \\\n",
    "        npp, sRef, A, Tarr_n, meanY, ds, lam2, device)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()               \n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()         \n",
    "    print('epoch: {}/{}, loss: {:.8f}'.format(j+1, epoch, loss.item()))\n",
    "    RMSE.append(loss.item())\n",
    "    \n",
    "# torch.save(model.state_dict(), os.path.join(save_path, ('dict_noise{}_eta{}_L{}_ps{}_natom{}_lam2{}_D_sparse{}_C_sparse{}.pth').\\\n",
    "#     format(noiseFrac, eta, L, patch_size, natom, lam2, D_sparse, C_sparse)))\n",
    "D = D.detach().squeeze().cpu().numpy() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the saved weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(save_path, 'dict_noise0.02_eta10_L20_ps20_natom50_lam20_D_sparse1_C_sparse1.pth')))\n",
    "# model.eval()\n",
    "# D = model(D0)\n",
    "# D = D.detach().squeeze().cpu().numpy() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruct the velocity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if noiseFrac == 0.02:\n",
    "    C_sparse = 25\n",
    "elif noiseFrac == 0.05:\n",
    "    C_sparse = 5\n",
    "else:\n",
    "    print('noiseFrac setting is not correct!')\n",
    "    \n",
    "X = omp_n(D, Yc, C_sparse)\n",
    "ss_b = D @ X + meanY\n",
    "ss_p_sum = np.zeros(ss.shape)\n",
    "\n",
    "for k in range(npatches):\n",
    "    ss_p_sum[patches[:, k], 0] = ss_p_sum[patches[:, k], 0] + ss_b[:, k]\n",
    "\n",
    "ss_f = (lam2 * ds + ss_p_sum)/(lam2 + npp)\n",
    "ss   = ss_f * vb  \n",
    "Tref = A @ (ss + sRef)\n",
    "normError_new = np.linalg.norm(Tref - Tarr_n)\n",
    "print('Inversion norm error: {}'.format(normError_new))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the updated dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vd(D, patch_size, natom//patch_size, 'us_ps20', save=save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot slice of velocity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = np.reshape(ss + 0.*ds*vb + sRef, (w1, w2))\n",
    "v_mask = np.reshape(vb, sTrue.shape)\n",
    "slice_sTrue = sTrue[:, 35]\n",
    "slice_Pre = y[:, 35]\n",
    "slice_mask = v_mask[:, 35]\n",
    "extent = 0, w1, 0, w2\n",
    "###########################plot result#######################################\n",
    "fig = plt.figure()\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "ax = fig.add_subplot()\n",
    "im = ax.imshow(y, extent=extent)\n",
    "ax.set_xlabel(\"Range (km)\")\n",
    "ax.set_ylabel(\"Range (km)\")\n",
    "ax.text(80, 5, '{:.2f}'.format(rmse(sTrue, y, v_mask)), fontsize=14)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax, fraction=0.046)\n",
    "plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# fig.savefig(save_path + 'slowness_natom_{}_noise_{}_sp_{}.pdf'\\\n",
    "#     .format( natom, noiseFrac, C_sparse), dpi=600)\n",
    "\n",
    "###########################polt slice###############################################\n",
    "fig = plt.figure()\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "ax4 = fig.add_subplot()\n",
    "ax4.plot(slice_sTrue, range(len(slice_sTrue)))\n",
    "ax4.plot(slice_Pre, range(len(slice_Pre)))\n",
    "ax4.text(0.6, 5, '{:.2f}'.format(rmse(slice_sTrue, slice_Pre, slice_mask)), fontsize=14)\n",
    "ax4.set_ylabel(\"Range (km)\")\n",
    "ax4.set_xlabel(\"Slowness (s/km)\")\n",
    "# ax4.set_title('Vertical slice RMSE:{:.4f}'.format(rmse(vsT, vsP, vmask)))\n",
    "ax4.legend(['True','Predict'])\n",
    "plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "ax4.margins(0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# fig.savefig(save_path + 'slice_natom_{}_noise_{}_sp_{}.pdf'\\\n",
    "#     .format(natom, noiseFrac, C_sparse), dpi=600)\n",
    "################################plot errors####################################\n",
    "# fig = plt.figure()\n",
    "# plt.rcParams['xtick.direction'] = 'in'\n",
    "# plt.rcParams['ytick.direction'] = 'in'\n",
    "# ax = fig.add_subplot()\n",
    "# im = ax.imshow((sTrue - y)*vb1, extent=extent)\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(im, cax=cax, fraction=0.046)\n",
    "# plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# fig.savefig(save_path + 'errors_natom_{}_noise_{}_sp_{}.pdf'\\\n",
    "#     .format(natom, noiseFrac, C_sparse), dpi=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion by LSQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lsqr  = np.reshape(ds*vb + sRef, (w1, w2))\n",
    "slice_lsqr = y_lsqr[:, 35]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "ax1 = fig.add_subplot()\n",
    "im1 = ax1.imshow(y_lsqr, extent=extent)\n",
    "ax1.set_xlabel(\"Range (km)\")\n",
    "ax1.set_ylabel(\"Range (km)\")\n",
    "ax1.text(80, 5, '{:.2f}'.format(rmse(sTrue, y_lsqr, v_mask)), fontsize=14)\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im1, cax=cax, fraction=0.046)\n",
    "plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# fig.savefig(save_path + 'LSQR_noise_{}.pdf'\\\n",
    "#     .format(noiseFrac), dpi=600)\n",
    "\n",
    "################################plot slice#######################################\n",
    "fig = plt.figure()\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "ax4 = fig.add_subplot()\n",
    "ax4.plot(slice_sTrue, range(len(slice_sTrue)))\n",
    "ax4.plot(slice_lsqr, range(len(slice_lsqr)))\n",
    "ax4.set_ylabel(\"Range (km)\")\n",
    "ax4.set_xlabel(\"Slowness (s/km)\")\n",
    "ax4.text(0.6, 5, '{:.2f}'.format(rmse(slice_sTrue, slice_lsqr, slice_mask)), fontsize=14)\n",
    "ax4.legend(['True','Predict'])\n",
    "ax4.margins(0)\n",
    "plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# fig.savefig(save_path + 'LSQR_slice_noise_{}.pdf'\\\n",
    "#     .format(noiseFrac), dpi=600)\n",
    "################################plot errors####################################\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot()\n",
    "# im = ax.imshow((sTrue - y2)*vb1, extent=extent)\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(im, cax=cax, fraction=0.046)\n",
    "# plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "# # plt.tight_layout()\n",
    "# plt.show()\n",
    "# fig.savefig(save_path + 'LSerrors_noise_{}.pdf'\\\n",
    "#     .format(noiseFrac), dpi=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion by dictionary learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tarr, A, vb, vb2 = survey_deisgn(64, sTrue, save_path=save_path)                                               \n",
    "stdNoise = np.mean(Tarr) * noiseFrac\n",
    "noise    = stdNoise * np.random.randn(Tarr.shape[0], Tarr.shape[1])\n",
    "Tarr_n   = Tarr + noise                                  \n",
    "Asum = np.sum(A, axis=1, keepdims=True)                                    # estimating referense slowness from travel time observations\n",
    "invAsum = np.linalg.pinv(Asum)\n",
    "sRef = invAsum @ Tarr_n                                     # Tarr_n: 1x2016 A: 2016x10000 vb:10000x1\n",
    "#######################################################################################\n",
    "w1, w2 = sTrue.shape\n",
    "patch_size = 10\n",
    "patches  = getPatches(w1, w2, patch_size)        # calculating image patch indices\n",
    "percZero = patchSamp(A, patches)       # percentage ray coverage in patches\n",
    "ss = np.zeros((vb.size, 1))\n",
    "npp, npatches = patches.shape\n",
    "nrays, npix   = A.shape\n",
    "normError = [np.linalg.norm(Tarr_n - A @ (ss + sRef))]\n",
    "print('Trave time initinal error: {}'.format(normError))\n",
    "############################################################\n",
    "epoch = 50\n",
    "natom = 150\n",
    "iters = 50\n",
    "lam2  = 0\n",
    "D_sparse = 1\n",
    "C_sparse = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iters):\n",
    "    dt  = Tarr_n - A @ (ss + sRef)\n",
    "    spA = csc_matrix(A)\n",
    "    ds  = lsqr(spA, dt, damp=10, iter_lim=1e3)[0]\n",
    "    ds  = np.expand_dims(ds, axis=1)\n",
    "    sg = ds + ss\n",
    "    Y   = sg.flatten()[patches]\n",
    "    meanY = np.mean(Y, axis=0, keepdims=True)\n",
    "    Yc = Y - meanY\n",
    "    Yl = Yc[:, percZero <= 0.1]\n",
    "    D = itkm(Yl, natom, 2, 50)\n",
    "    X = omp_n(D, Yc, 2)\n",
    "    ss_b = D @ X + meanY\n",
    "    ss_p_sum = np.zeros(ss.shape)\n",
    "    \n",
    "    for k in range(npatches):\n",
    "        ss_p_sum[patches[:, k], 0] = ss_p_sum[patches[:, k], 0] + ss_b[:, k]\n",
    "    \n",
    "    ss_f = (lam2 * sg + ss_p_sum)/(lam2 + npp)\n",
    "    ss   = ss_f * vb2\n",
    "    Tref = A @ (ss + sRef)\n",
    "    normError_new = np.linalg.norm(Tref - Tarr_n)\n",
    "    print('Iter: {}, inversion norm error: {}'.format(i+1, normError_new))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vd(D, patch_size, natom//patch_size, 'DL', save=save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot inversion results by dictionary learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_DL  = np.reshape(ss + sRef, (w1, w2))\n",
    "v_mask = np.reshape(vb, sTrue.shape)\n",
    "slice_sTrue = sTrue[:, 35]\n",
    "slice_mask = v_mask[:, 35]\n",
    "slice_DL = y_DL[:, 35]\n",
    "fig = plt.figure()\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "extent = 0, w1, 0, w2\n",
    "ax = fig.add_subplot()\n",
    "im = ax.imshow(y_DL, extent=extent)\n",
    "ax.set_xlabel(\"Range (km)\")\n",
    "ax.set_ylabel(\"Range (km)\")\n",
    "ax.text(80, 5, '{:.2f}'.format(rmse(sTrue, y_DL, v_mask)), fontsize=14)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax, fraction=0.046)\n",
    "plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(save_path + 'DL_iters_{}_natom_{}_noise_{}_ps_{}.pdf'\\\n",
    "    .format(iters, natom, noiseFrac, patch_size))\n",
    "\n",
    "###########################polt slice###############################################\n",
    "fig = plt.figure()\n",
    "ax4 = fig.add_subplot()\n",
    "ax4.plot(slice_sTrue, range(len(slice_sTrue)))\n",
    "ax4.plot(slice_DL, range(len(slice_DL)))\n",
    "ax4.text(0.6, 5, '{:.2f}'.format(rmse(slice_sTrue, slice_DL, slice_mask)), fontsize=14)\n",
    "ax4.set_ylabel(\"Range (km)\")\n",
    "ax4.set_xlabel(\"Slowness (s/km)\")\n",
    "ax4.legend(['True','Dicttionary learning'])\n",
    "plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "ax4.margins(0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(save_path + 'DL_slice_noise_{}.pdf'.format(noiseFrac))\n",
    "################################plot errors####################################\n",
    "# fig = plt.figure()\n",
    "# plt.rcParams['xtick.direction'] = 'in'\n",
    "# plt.rcParams['ytick.direction'] = 'in'\n",
    "# ax = fig.add_subplot()\n",
    "# im = ax.imshow((sTrue - y)*vb1, extent=extent)\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(im, cax=cax, fraction=0.046)\n",
    "# plt.tick_params(top=True,bottom=True,left=True,right=True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# fig.savefig(save_path + 'SDerrors_iters_{}_natom_{}_noise_{}_ps_{}.pdf'\\\n",
    "#     .format(iters, natom, noiseFrac, patch_size), dpi=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot slices of all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(sRef[0,0]*np.ones(len(slice_sTrue)), range(len(slice_sTrue)),'k')\n",
    "ax.plot(slice_sTrue, range(len(slice_sTrue)))\n",
    "ax.plot(slice_lsqr, range(len(slice_lsqr)))\n",
    "ax.plot(slice_DL, range(len(slice_DL)))\n",
    "ax.plot(slice_Pre, range(len(slice_Pre)))\n",
    "ax.set_ylabel(\"Range (km)\")\n",
    "ax.set_xlabel(\"Slowness (s/km)\")\n",
    "ax.legend(['Reference slowness', 'True','LSQR','Dictionary learning', 'The proposed method'])\n",
    "plt.tick_params(top=True, bottom=True, left=True, right=True)\n",
    "ax.margins(0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(save_path + 'slice_of_all_methods_noise_{}.pdf'.format(noiseFrac))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "807cc6a481f25a5b222cd58a3949a299ed2f2634387eaba6775d5c01f71eeb59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
